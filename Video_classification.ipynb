{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdz2hzEpexZh05vAggtP/O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/testgithubprecious/Ml_projects/blob/main/Video_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sm6VtlMEtsFp"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Install if not already: pip install torch torchvision opencv-python\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# ------------------------------\n",
        "# Define a basic 3D CNN\n",
        "# ------------------------------\n",
        "class Simple3DCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(Simple3DCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv3d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool1 = nn.MaxPool3d(2)\n",
        "        self.conv2 = nn.Conv3d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool2 = nn.MaxPool3d(2)\n",
        "        self.fc1 = nn.Linear(64 * 4 * 28 * 28, 256)  # Adjust if input frames change\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.conv1(x)))  # -> [B, 32, T/2, H/2, W/2]\n",
        "        x = self.pool2(F.relu(self.conv2(x)))  # -> [B, 64, T/4, H/4, W/4]\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n",
        "\n",
        "# ------------------------------\n",
        "# Preprocessing: load video frames\n",
        "# ------------------------------\n",
        "def load_video_tensor(video_path, num_frames=16, resize=(112, 112)):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    step = max(total_frames // num_frames, 1)\n",
        "\n",
        "    for i in range(num_frames):\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, i * step)\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame = cv2.resize(frame, resize)\n",
        "        frame = frame[:, :, ::-1]  # BGR -> RGB\n",
        "        frames.append(frame)\n",
        "    cap.release()\n",
        "\n",
        "    # Normalize and convert to tensor\n",
        "    frames = np.stack(frames).astype(np.float32) / 255.0\n",
        "    frames = np.transpose(frames, (3, 0, 1, 2))  # [C, T, H, W]\n",
        "    return torch.tensor(frames).unsqueeze(0)  # [1, C, T, H, W]\n",
        "\n",
        "# ------------------------------\n",
        "# Example usage\n",
        "# ------------------------------\n",
        "video_path = 'sample_video.mp4'  # Replace with your video\n",
        "video_tensor = load_video_tensor(video_path)\n",
        "\n",
        "# Initialize model and predict\n",
        "model = Simple3DCNN(num_classes=5)  # Assume 5 action classes\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(video_tensor)\n",
        "    prediction = torch.argmax(outputs, dim=1).item()\n",
        "\n",
        "print(f\"ðŸŽ¥ Predicted Class ID: {prediction}\")"
      ]
    }
  ]
}